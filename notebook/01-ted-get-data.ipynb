{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config for project: solar_forecast\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# load config yaml file\n",
    "config_file = \"/Users/macbook/Development/solar_power_forecast_ML/config.yaml\"\n",
    "with open(config_file, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Acces API url\n",
    "api_url = config['api_url']\n",
    "\n",
    "# Access data path\n",
    "raw_data_path = config['paths']['raw_data_path']\n",
    "interim_data_path = config['paths']['interim_data_path']\n",
    "\n",
    "\n",
    "print(f\"Loaded config for project: {config['project_info']['project_name']}\")\n",
    "if raw_data_path is True:\n",
    "    print(f\"Raw data path: {raw_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call variables:\n",
    "- Choose fromat between csv or json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define variables parameters for API call\n",
    "location_name = config['project_info']['location_name'] # use for file naming, not for API call \n",
    "\n",
    "latitude = 52.516275       # Brandenburger Tor lattitude\n",
    "longitude = 13.377704      # Brandenburger Tor longitude       \n",
    "start_year = 2005\n",
    "end_year = 2023  \n",
    "response_type = 'seriescalc' #'seriescalc': hourly radiation; ''DRcalc': daily radiation; 'tmy': typical meteorological year\n",
    "\n",
    "format = 'csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call has been made to: https://re.jrc.ec.europa.eu/api/v5_3/seriescalc \n",
      "API call successful\n"
     ]
    }
   ],
   "source": [
    "api_url = config['api_url']\n",
    "base_url = os.path.join(api_url,response_type)\n",
    "\n",
    "if base_url:\n",
    "    print(f\"API call has been made to: {base_url} \")\n",
    "\n",
    "# Parameters for a 35Â° tilt system\n",
    "pvgid_params = dict(\n",
    "    lat=latitude,\n",
    "    lon=longitude,\n",
    "    #usehorizon=           # No mandatory. Calculate taking into account shadows from high horizon. Value of 1 for \"yes\"\n",
    "    startyear=start_year, \n",
    "    endyear=end_year,   \n",
    "    pvcalculation=1,       # 0: only solar radiation, 1: add PV production\n",
    "    peakpower=4.5,          # Nominal power of the PV system, in kWp.\n",
    "    mountingplace='free', # Example: free-standing (or 'building')\n",
    "    loss=14,              # % system losses \n",
    "    slope=35,             # Example: 35 degree tilt from horizontal\n",
    "    azimuth=0,              # Example: Facing South (0 degrees)\n",
    "    components=1,           #1: outputs beam, diffuse and reflected radiation components. 0: only global values.\n",
    "    hourly=1,\n",
    "    outputformat=format     #basic: for non comment csv output, json or csv\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = requests.get(base_url, params=pvgid_params, timeout=30)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"API call successful\")\n",
    "        if format == 'csv':\n",
    "            data = response.text\n",
    "        elif format == 'json':\n",
    "            data = response.json()\n",
    "    else:\n",
    "        print(f\"API call failed with status code: {response.status_code}, server response: {response.text}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred during the API request: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save API call data \n",
    "- save raw file locally from call\n",
    "- remove headers & footers (for csv file)\n",
    "- save to data/interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the data file naming\n",
    "file_type = f\".{format}\" # csv or json.refers to api call format\n",
    "\n",
    "raw_data_path = config['paths']['raw_data_path']\n",
    "raw_file_name = f\"raw_{location_name}_{response_type}{file_type}\"\n",
    "raw_data_file = f\"{raw_data_path}/{raw_file_name}\"\n",
    "\n",
    "interim_data_path = config['paths']['interim_data_path']\n",
    "interim_file_name = f\"no_headers_{location_name}_{response_type}{file_type}\"\n",
    "interim_data_file = f\"{interim_data_path}/{interim_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 166536 entries, 0 to 166535\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   time    166536 non-null  datetime64[ns]\n",
      " 1   P       166536 non-null  float64       \n",
      " 2   Gb(i)   166536 non-null  float64       \n",
      " 3   Gd(i)   166536 non-null  float64       \n",
      " 4   Gr(i)   166536 non-null  float64       \n",
      " 5   H_sun   166536 non-null  float64       \n",
      " 6   T2m     166536 non-null  float64       \n",
      " 7   WS10m   166536 non-null  float64       \n",
      " 8   Int     166536 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8)\n",
      "memory usage: 11.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create a function to convert time column\n",
    "def convert_time_column(data, time_format): \n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], format=time_format)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved locally: /Users/macbook/Development/solar_power_forecast_ML/data/01_raw/raw_brandenburger_gate_seriescalc.csv\n",
      "File saved locally: /Users/macbook/Development/solar_power_forecast_ML/data/02_interim/no_headers_brandenburger_gate_seriescalc.csv\n"
     ]
    }
   ],
   "source": [
    "# save raw file locally in csv or json\n",
    "if format == 'csv':\n",
    "    with open(raw_data_file, 'w' , encoding='utf-8') as csv_file:\n",
    "        csv_file.write(response.text)\n",
    "        print(f\"File saved locally: {raw_data_file}\")\n",
    "        \n",
    "    # remove the comments, change time column to timestamp and make a copy in data/interim\n",
    "    with open(raw_data_file, 'r', encoding='utf-8') as csv_file:    \n",
    "        data = pd.read_csv(csv_file, skiprows=10, skipfooter=12, sep=',', engine='python')\n",
    "        data = convert_time_column(data, time_format=\"%Y%m%d:%H%M\")\n",
    "        data.to_csv(interim_data_file,index=False)\n",
    "        print(f\"File saved locally: {interim_data_file}\")\n",
    "\n",
    "elif format == 'json':\n",
    "    with open(raw_data_file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=2)\n",
    "        print(f\"File saved locally: {raw_data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the JSON API endpoints\n",
    "\n",
    "NOTE: those cells were used to explore the API endpoints json and its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/solar_power_forecast_ML/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'inputs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m inputs = \u001b[38;5;28mlist\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.items())\n\u001b[32m      2\u001b[39m inputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/solar_power_forecast_ML/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/solar_power_forecast_ML/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'inputs'"
     ]
    }
   ],
   "source": [
    "inputs = list(data['inputs'].items())\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data['outputs'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_keys = list(data['outputs']['hourly'])\n",
    "print(type(monthly_keys))\n",
    "\n",
    "for elements in monthly_keys:\n",
    "    list(elements)\n",
    "    print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
